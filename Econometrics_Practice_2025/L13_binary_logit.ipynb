{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logit模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import optimize\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm # 使用 statsmodels 包实现 Logit 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_hours</th>\n",
       "      <th>pass_exam</th>\n",
       "      <th>pass_prob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.621781</td>\n",
       "      <td>1</td>\n",
       "      <td>0.353755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.655000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.932390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.123958</td>\n",
       "      <td>0</td>\n",
       "      <td>0.802052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.190609</td>\n",
       "      <td>0</td>\n",
       "      <td>0.657571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.092130</td>\n",
       "      <td>0</td>\n",
       "      <td>0.138680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   study_hours  pass_exam  pass_prob\n",
       "0     3.621781          1   0.353755\n",
       "1     7.655000          1   0.932390\n",
       "2     6.123958          0   0.802052\n",
       "3     5.190609          0   0.657571\n",
       "4     2.092130          0   0.138680"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 设置随机种子以确保结果可重现\n",
    "np.random.seed(42)\n",
    "\n",
    "# 生成自变量：学习时间（小时）\n",
    "n_samples = 50  # 样本量\n",
    "study_hours_new = np.random.uniform(1, 8, n_samples)\n",
    "\n",
    "# 生成线性预测值\n",
    "true_beta0 = -3.5  # 真实截距\n",
    "true_beta1 = 0.8   # 真实斜率\n",
    "linear_pred = true_beta0 + true_beta1 * study_hours_new\n",
    "\n",
    "# 计算通过概率\n",
    "pass_prob = 1 / (1 + np.exp(-linear_pred))\n",
    "\n",
    "# 生成二元因变量：是否通过考试\n",
    "pass_exam_new = np.random.binomial(1, pass_prob) # 生成服从二项分布的随机数的函数\n",
    "\n",
    "# 创建DataFrame\n",
    "df_logit = pd.DataFrame({\n",
    "    'study_hours': study_hours_new,\n",
    "    'pass_exam': pass_exam_new,\n",
    "    'pass_prob': pass_prob\n",
    "})\n",
    "\n",
    "df_logit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Newton方法结果 ===\n",
      "beta0 = -4.1170\n",
      "beta1 = 0.8870\n",
      "最大对数似然值 = -22.5005\n",
      "\n",
      "=== BFGS方法结果 ===\n",
      "beta0 = -4.1171\n",
      "beta1 = 0.8870\n",
      "最大对数似然值 = -22.5005\n",
      "\n",
      "=== 参数差异 ===\n",
      "beta0差异: 0.000046\n",
      "beta1差异: 0.000008\n",
      "对数似然差异: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# 准备数据\n",
    "X_new = sm.add_constant(study_hours_new)\n",
    "y_new = pass_exam_new\n",
    "\n",
    "# 拟合 Logit 模型\n",
    "logit_model_new = sm.Logit(y_new, X_new)\n",
    "\n",
    "# 使用不同方法拟合并比较结果\n",
    "result_newton_new = logit_model_new.fit(method='newton', disp=0)\n",
    "result_bfgs_new = logit_model_new.fit(method='bfgs', disp=0)\n",
    "\n",
    "# # 输出两种方法的结果比较\n",
    "# print(\"\\n=== Newton方法结果 ===\")\n",
    "# print(result_newton_new.summary())\n",
    "\n",
    "# print(\"\\n=== BFGS方法结果 ===\")\n",
    "# print(result_bfgs_new.summary())\n",
    "\n",
    "# 输出两种方法的结果比较\n",
    "print(\"\\n=== Newton方法结果 ===\")\n",
    "print(f\"beta0 = {result_newton_new.params[0]:.4f}\")\n",
    "print(f\"beta1 = {result_newton_new.params[1]:.4f}\")\n",
    "print(f\"最大对数似然值 = {result_newton_new.llf:.4f}\")\n",
    "\n",
    "print(\"\\n=== BFGS方法结果 ===\")\n",
    "print(f\"beta0 = {result_bfgs_new.params[0]:.4f}\")\n",
    "print(f\"beta1 = {result_bfgs_new.params[1]:.4f}\")\n",
    "print(f\"最大对数似然值 = {result_bfgs_new.llf:.4f}\")\n",
    "\n",
    "# 比较参数差异\n",
    "print(\"\\n=== 参数差异 ===\")\n",
    "print(f\"beta0差异: {abs(result_newton_new.params[0] - result_bfgs_new.params[0]):.6f}\")\n",
    "print(f\"beta1差异: {abs(result_newton_new.params[1] - result_bfgs_new.params[1]):.6f}\")\n",
    "print(f\"对数似然差异: {abs(result_newton_new.llf - result_bfgs_new.llf):.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **模型：**\n",
    "  $$P(y_i=1|x_i) = \\frac{e^{\\beta_0+\\beta_1 x_i}}{1+e^{\\beta_0+\\beta_1 x_i}}$$\n",
    "\n",
    "- **似然函数：**\n",
    "  $$L(\\beta_0,\\beta_1) = \\prod_{i=1}^{50} \\left[\\frac{e^{\\beta_0+\\beta_1 x_i}}{1+e^{\\beta_0+\\beta_1 x_i}}\\right]^{y_i}\\left[\\frac{1}{1+e^{\\beta_0+\\beta_1 x_i}}\\right]^{1-y_i}$$\n",
    "\n",
    "- **对数似然：**\n",
    "  $$\\ln L = \\sum_{i=1}^{n} \\left[ y_i \\cdot \\ln \\left( \\frac{e^{\\beta_0 + \\beta_1 x_i}}{1 + e^{\\beta_0 + \\beta_1 x_i}} \\right) + (1 - y_i) \\cdot \\ln \\left( \\frac{1}{1 + e^{\\beta_0 + \\beta_1 x_i}} \\right) \\right]$$\n",
    "  $$\\ln L = \\sum_{i=1}^{50} \\{y_i(\\beta_0+\\beta_1 x_i) - \\ln(1+e^{\\beta_0+\\beta_1 x_i})\\}$$\n",
    "\n",
    "- **梯度（一阶导数）：**\n",
    "  $$\\frac{\\partial \\ln L}{\\partial \\beta_0} = \\sum_{i=1}^{50} \\left[y_i - \\frac{e^{\\beta_0+\\beta_1 x_i}}{1+e^{\\beta_0+\\beta_1 x_i}}\\right] = \\sum_{i=1}^{50} (y_i - p_i)$$\n",
    "  \n",
    "  $$\\frac{\\partial \\ln L}{\\partial \\beta_1} = \\sum_{i=1}^{50} \\left[y_i x_i - \\frac{e^{\\beta_0+\\beta_1 x_i}}{1+e^{\\beta_0+\\beta_1 x_i}}x_i\\right] = \\sum_{i=1}^{50} (y_i - p_i)x_i$$\n",
    "\n",
    "  其中 $p_i = \\frac{e^{\\beta_0+\\beta_1 x_i}}{1+e^{\\beta_0+\\beta_1 x_i}}$ 是第 $i$ 个观测的预测概率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "优化方法最终结果:\n",
      "beta0 = -4.1171\n",
      "beta1 = 0.8870\n",
      "最大对数似然值 = -22.5005\n",
      "收敛状态: True\n",
      "迭代次数: 12\n",
      "\n",
      "与真实参数比较:\n",
      "beta0: 真实值=-3.5000, 估计值=-4.1171, 差异=0.6171\n",
      "beta1: 真实值=0.8000, 估计值=0.8870, 差异=0.0870\n"
     ]
    }
   ],
   "source": [
    "# 优化的Logit模型对数似然函数（向量化实现）\n",
    "def neg_log_likelihood_optimized(params, x, y):\n",
    "    beta0, beta1 = params\n",
    "    linear_pred = beta0 + beta1 * x\n",
    "    \n",
    "    # 直接按照对数似然公式计算: Σ[y_i(β₀+β₁x_i) - ln(1+e^(β₀+β₁x_i))]\n",
    "    log_likelihood = np.sum(y * linear_pred - np.log(1 + np.exp(linear_pred)))\n",
    "    # print(f\"参数: beta0={beta0:.4f}, beta1={beta1:.4f}, 对数似然: {log_likelihood:.4f}\")\n",
    "    return -log_likelihood\n",
    "\n",
    "# 计算梯度以加速优化\n",
    "def neg_log_likelihood_grad(params, x, y):\n",
    "    beta0, beta1 = params\n",
    "    linear_pred = beta0 + beta1 * x\n",
    "    p = 1 / (1 + np.exp(-linear_pred))  # 计算预测概率\n",
    "    # 梯度计算\n",
    "    grad_beta0 = -np.sum(y - p)\n",
    "    grad_beta1 = -np.sum((y - p) * x)\n",
    "    return np.array([grad_beta0, grad_beta1])\n",
    "\n",
    "# 使用DataFrame中的数据\n",
    "x = df_logit['study_hours'].values\n",
    "y = df_logit['pass_exam'].values\n",
    "\n",
    "# 初始猜测值\n",
    "initial_guess = [0, 0]\n",
    "\n",
    "\n",
    "result_optimized = optimize.minimize(\n",
    "    neg_log_likelihood_optimized, \n",
    "    initial_guess, \n",
    "    args=(x, y),\n",
    "    method='L-BFGS-B',\n",
    "    jac=neg_log_likelihood_grad,\n",
    "    options={'disp': True}\n",
    ")\n",
    "\n",
    "# 提取最优参数\n",
    "beta0_opt, beta1_opt = result_optimized.x\n",
    "print(\"\\n优化方法最终结果:\")\n",
    "print(f\"beta0 = {beta0_opt:.4f}\")\n",
    "print(f\"beta1 = {beta1_opt:.4f}\")\n",
    "print(f\"最大对数似然值 = {-result_optimized.fun:.4f}\")\n",
    "print(f\"收敛状态: {result_optimized.success}\")\n",
    "print(f\"迭代次数: {result_optimized.nit}\")\n",
    "\n",
    "# 比较与真实参数的差异\n",
    "print(\"\\n与真实参数比较:\")\n",
    "print(f\"beta0: 真实值={true_beta0:.4f}, 估计值={beta0_opt:.4f}, 差异={abs(true_beta0-beta0_opt):.4f}\")\n",
    "print(f\"beta1: 真实值={true_beta1:.4f}, 估计值={beta1_opt:.4f}, 差异={abs(true_beta1-beta1_opt):.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv_io",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
